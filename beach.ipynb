{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ye1eiDudxcFZ"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "tf.keras.backend.set_floatx(\"float64\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "92MPWNQYxcFb"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "import math\n",
    "\n",
    "\n",
    "def load_img(path_to_img, max_dim):\n",
    "    image = tf.io.read_file(path_to_img)\n",
    "    image = tf.io.decode_image(\n",
    "        image, channels=3, dtype=tf.dtypes.float64, name=None, expand_animations=True\n",
    "    )\n",
    "    image = tf.image.convert_image_dtype(image, dtype=tf.float64, saturate=False)\n",
    "\n",
    "    print(\"Initial shape: \", image.shape)\n",
    "    max_dim = max_dim\n",
    "    image = tf.expand_dims(image, 0)\n",
    "    height = image.shape[1]\n",
    "    weight = image.shape[2]\n",
    "    if height > weight:\n",
    "        weight = (weight / height) * max_dim\n",
    "        height = max_dim\n",
    "    elif weight > height:\n",
    "        height = (height / weight) * max_dim\n",
    "        weight = max_dim\n",
    "    else:\n",
    "        height = max_dim\n",
    "        weight = max_dim\n",
    "    image = tf.image.resize(image, [math.trunc(height), math.trunc(weight)])\n",
    "    img = tf.cast(image, tf.float64)\n",
    "    print(\"Final shape: \", image.shape)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GJH7aOM2xcFb",
    "outputId": "2ebb8ddc-eb35-472c-875c-ae05dadd56c6"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "content_image = load_img(\"cont_beach.jpg\", 1024)\n",
    "style_image = load_img(\"beach.jpg\", 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 229
    },
    "id": "odiHH_4RxcFc",
    "outputId": "d0089636-83ef-4b84-a6a0-bf92c8387f94"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "# you can give axis attribute if you wanna squeeze in specific dimension\n",
    "content = np.squeeze(content_image)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.imshow(content)\n",
    "style = np.squeeze(style_image)\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.imshow(style)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ql9IiICbxcFe",
    "outputId": "16ed5622-f72c-49b2-ccc1-840cac84e09f"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "vgg = tf.keras.applications.VGG19(include_top=True, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I2D7GZ5CxcFf",
    "outputId": "b6a3d8ae-56ca-42e3-8907-d5c5804707cd",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "tf.keras.models.Model.summary(vgg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IIZfN-ztxcFf"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "\n",
    "\n",
    "def preprcoess_input(data):\n",
    "    image =  tf.keras.applications.vgg19.preprocess_input(tf.cast(data*255, dtype= tf.int64), data_format=None)\n",
    "    rescale_image = tf.image.resize(image,[vgg.layers[0].get_output_at(0).get_shape()[1],vgg.layers[0].get_output_at(0).get_shape()[2]])\n",
    "    return image,rescale_image\n",
    "\n",
    "\n",
    "processed_input = preprcoess_input(content_image)\n",
    "content_image_pp = processed_input[0]\n",
    "content_image_rs = processed_input[1]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q33vPvCOxcFg"
   },
   "outputs": [],
   "source": [
    "predicted_probabilities = vgg(content_image_rs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "K6XhuEfsxcFg",
    "outputId": "ace7939c-f770-4959-f11b-af2750f32d3b"
   },
   "outputs": [],
   "source": [
    "predicted_top_10 = tf.keras.applications.vgg19.decode_predictions(\n",
    "    predicted_probabilities.numpy(), top=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ltBvxNgGxcFg",
    "outputId": "34d60e2c-523f-4d80-b9ff-13597e993665"
   },
   "outputs": [],
   "source": [
    "[(class_name, prob) for (number, class_name, prob) in predicted_top_10[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8czejhdxcFh"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "processed_input_style = preprcoess_input(style_image)\n",
    "style_image_pp = processed_input_style[0]\n",
    "style_image_rs = processed_input_style[1]\n",
    "predicted_probabilities_style = vgg(style_image_rs)\n",
    "predicted_top_10_style = tf.keras.applications.vgg19.decode_predictions(\n",
    "    predicted_probabilities_style.numpy(), top=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-9WxLsZMxcFh",
    "outputId": "66f34b33-1f08-4dd6-a9bf-403b5bdf7ea5"
   },
   "outputs": [],
   "source": [
    "[(class_name, prob) for (number, class_name, prob) in predicted_top_10_style[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "J4TW0r1axcFi",
    "outputId": "283994bc-3989-47ff-8f33-803ffeb7d1fd"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "vgg_false = tf.keras.applications.VGG19(include_top=False, weights=\"imagenet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AS5dTYMKxcFi",
    "outputId": "2acce2aa-6da0-4b45-c973-9b4229bbabc8"
   },
   "outputs": [],
   "source": [
    "for i in vgg_false.layers:\n",
    "    print(i.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d0exgNOrxcFi"
   },
   "source": [
    "**Checkpoint:** Your output should look as follows:\n",
    "```\n",
    "input_2\n",
    "block1_conv1\n",
    "block1_conv2\n",
    "block1_pool\n",
    "block2_conv1\n",
    "block2_conv2\n",
    "block2_pool\n",
    "block3_conv1\n",
    "block3_conv2\n",
    "block3_conv3\n",
    "block3_conv4\n",
    "block3_pool\n",
    "block4_conv1\n",
    "block4_conv2\n",
    "block4_conv3\n",
    "block4_conv4\n",
    "block4_pool\n",
    "block5_conv1\n",
    "block5_conv2\n",
    "block5_conv3\n",
    "block5_conv4\n",
    "block5_pool\n",
    "```\n",
    "\n",
    "This output includes all layers, that can be added to $L_\\mathrm{content}$ and $L_\\mathrm{style}$. For the moment, let us fix the following:\n",
    "\n",
    "11. Create two lists ```content_layers``` and ```style_layers```. Initialize ```content_layers``` with a single element ```\"block4_conv2\"``` and ```style_layers``` with five elements ```\"block1_conv1\", ..., \"block5_conv1\"```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "maYhrJ_GxcFi"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "content_layers = [\"block3_conv4\"]\n",
    "style_layers = [\n",
    "    \"block1_conv2\",\n",
    "    \"block2_conv2\",\n",
    "    \"block3_conv2\",\n",
    "    \"block4_conv2\",\n",
    "    \"block5_conv2\",\n",
    "]\n",
    "#content_layers = [\"block4_conv2\"]\n",
    "#style_layers = [    \"block1_conv1\",    \"block2_conv1\",    \"block3_conv1\",\n",
    "   # \"block4_conv1\",\n",
    "   # \"block5_conv1\",\n",
    "#]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H_eIoCxAxcFj"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "def vgg_layers(layer_names):\n",
    "    output_layer = []\n",
    "    for i in layer_names:\n",
    "        output_layer.append(vgg_false.get_layer(i).output)\n",
    "    model = tf.keras.Model([vgg_false.input], output_layer)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kdJar5kLxcFj",
    "outputId": "29f38185-438a-48f0-f5b0-660cc61ef568"
   },
   "outputs": [],
   "source": [
    "vgg_layers(style_layers).output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uJ_HXsldxcFj"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "def gram_matrix(input_tensor):\n",
    "    e = tf.linalg.einsum(\"xijc,xijs->xcs\", input_tensor, input_tensor)\n",
    "    #     e = tf.linalg.einsum(\"xijc,xjks->xcs\", input_tensor, input_tensor)\n",
    "    input_shape = tf.cast(tf.shape(input_tensor), dtype=tf.float64)\n",
    "    #     print(input_shape)\n",
    "    return e / (input_shape[1] * input_shape[2] * input_shape[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KF7SLbMexcFj",
    "outputId": "81df1f9a-dc67-48df-9c69-d0aa5aa535d6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gram_matrix(vgg_layers(style_layers)(content_image)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UTVHHq57xcFk"
   },
   "outputs": [],
   "source": [
    "# replace all occurences of None\n",
    "class StyleContentModel(tf.keras.models.Model):\n",
    "    def __init__(self, style_layers, content_layers):\n",
    "        super(StyleContentModel, self).__init__()\n",
    "        self.vgg = vgg_layers(style_layers + content_layers)\n",
    "        self.style_layers = style_layers\n",
    "        self.content_layers = content_layers\n",
    "        self.num_style_layers = len(style_layers)\n",
    "        self.vgg.trainable = False\n",
    "\n",
    "    def call(self, inputs):\n",
    "        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs * 255)\n",
    "        outputs = self.vgg(preprocessed_input)\n",
    "        style_outputs, content_outputs = (\n",
    "            outputs[: self.num_style_layers],\n",
    "            outputs[self.num_style_layers :],\n",
    "        )\n",
    "        style_outputs = [gram_matrix(i) for i in style_outputs]\n",
    "        content_dict = {\n",
    "            content_name: value\n",
    "            for content_name, value in zip(self.content_layers, content_outputs)\n",
    "        }\n",
    "        style_dict = {\n",
    "            style_name: value\n",
    "            for style_name, value in zip(self.style_layers, style_outputs)\n",
    "        }\n",
    "        return {\"content\": content_dict, \"style\": style_dict}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XI3PyqW6xcFk"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "extractor = StyleContentModel(style_layers, content_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rOIu4zEvxcFk",
    "outputId": "934c0a5f-5e72-4297-b756-b8273a91f8c6"
   },
   "outputs": [],
   "source": [
    "extractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZHRSCug0xcFl"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "# style_targets = extractor(style_image)\n",
    "style_targets = extractor(style_image)['style']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zD6NkeBmxcFl",
    "outputId": "1fec74f7-7549-4efa-e6ce-75f607e8979a"
   },
   "outputs": [],
   "source": [
    "style_targets[\"block4_conv2\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eEnLwfO1xcFm"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "content_targets = extractor(content_image)[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KM_sJCe3xcFm",
    "outputId": "d35db833-e49e-4322-d7d2-00c021ea4208"
   },
   "outputs": [],
   "source": [
    "content_targets[\"block5_conv4\"][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Az0qbj0vxcFm"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "image = tf.Variable(content_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mgwi0WWDxcFn"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "content_weight = 1e3\n",
    "style_weight = 1e-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3UTXeBwPxcFn"
   },
   "source": [
    "20. Assign the optimizer ```tf.optimizers.Adam``` with parameters ```learning_rate=0.02```, ```beta_1=0.99``` and ```epsilon=1e-1``` to ```opt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "th_xnoqcxcFn"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "opt = tf.optimizers.experimental.Nadam(learning_rate=0.04, beta_1=0.99, epsilon=1e-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SFq3hNWJxcFn",
    "outputId": "fec92dfd-b24c-4585-dc31-d48e66209ff2"
   },
   "outputs": [],
   "source": [
    "opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uulgl-HqxcFn"
   },
   "outputs": [],
   "source": [
    "# # YOUR CODE\n",
    "# def clip_0_1(image):\n",
    "#     values = tf.clip_by_value(image, clip_value_min=0, clip_value_max=1)\n",
    "#     return values\n",
    "# YOUR CODE\n",
    "def clip_0_1(image):\n",
    "    values = tf.clip_by_value(image, 0, 1)\n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1JX7fHPlxcFo"
   },
   "outputs": [],
   "source": [
    "# replace all occurences of None\n",
    "def style_content_loss(\n",
    "    outputs, style_targets, content_targets, style_weight, content_weight\n",
    "):\n",
    "    style_outputs = outputs[\"style\"]\n",
    "    content_outputs = outputs[\"content\"]\n",
    "\n",
    "    style_loss = tf.add_n(\n",
    "        [\n",
    "            tf.reduce_sum((style_outputs[name] - style_targets[name]) ** 2)\n",
    "            for name in style_outputs.keys()\n",
    "        ]\n",
    "    )\n",
    "    style_loss *= style_weight / (4 * len(style_outputs))\n",
    "    content_loss = tf.add_n(\n",
    "        [\n",
    "            tf.reduce_sum((content_outputs[name] - content_targets[name]) ** 2)\n",
    "            for name in content_outputs.keys()\n",
    "        ]\n",
    "    )\n",
    "    content_loss *= content_weight / (2 * len(content_outputs))\n",
    "    loss = style_loss + content_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJsTQboRxcFo"
   },
   "outputs": [],
   "source": [
    "# replace all occurences of None\n",
    "@tf.function()\n",
    "def train_step(image, opt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(image)\n",
    "        loss = style_content_loss(\n",
    "                        outputs=outputs,\n",
    "            style_targets=style_targets,\n",
    "            content_targets=content_targets,\n",
    "            style_weight=style_weight,\n",
    "            content_weight=content_weight,\n",
    "        )\n",
    "    grad = tape.gradient(loss, image)\n",
    "    opt.apply_gradients([(grad, image)])\n",
    "    image.assign(clip_0_1(image))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QJiyFlGuxcFp"
   },
   "outputs": [],
   "source": [
    "loops = 200\n",
    "iters_per_loop = 12\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(\n",
    "    \"logs\" + f\"/stw{style_weight}_cow{content_weight}\" + \"my_image\"\n",
    ")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "for loop in range(loops):\n",
    "    tf.summary.image(\"image\", data=image, step=loop * iters_per_loop)\n",
    "    for it in range(iters_per_loop):\n",
    "        # YOUR CODE\n",
    "        loss = train_step(image, opt)\n",
    "        tf.summary.scalar(\"loss\", data=loss, step=loop * iters_per_loop + it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EJGLbrYNxcFp"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QFcCF1TNxcFp"
   },
   "source": [
    "25. Initialize ```tv_weight = 1e3```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "URsUvjEOxcFp"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "tv_weight = 1e3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ITl7aBH4xcFq"
   },
   "source": [
    "26. Redefine ```train_step```. The only difference above should be an additional loss term ```tv_weight * tf.cast(tf.image.total_variation(image)[0], tf.float64)```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "allqGfgXxcFq"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "\n",
    "# replace all occurences of None\n",
    "@tf.function()\n",
    "def train_step(image, opt):\n",
    "    with tf.GradientTape() as tape:\n",
    "        outputs = extractor(image)\n",
    "        loss = style_content_loss(\n",
    "            outputs=outputs,\n",
    "            style_targets=style_targets,\n",
    "            content_targets=content_targets,\n",
    "            style_weight=style_weight,\n",
    "            content_weight=content_weight,\n",
    "        ) + tv_weight * tf.cast(tf.image.total_variation(image)[0], tf.float64)\n",
    "    grad = tape.gradient(loss, image)\n",
    "    opt.apply_gradients([(grad, image)])\n",
    "    image.assign(clip_0_1(image))\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Wumx5mCxcFq"
   },
   "source": [
    "27. Initialize ```image``` again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gzc9RZeHxcFq"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "image = tf.Variable(content_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNysWwMDxcFq"
   },
   "source": [
    "28. Repeat step 24. and view the results. Don't forget to re-initialize ```opt```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2P7C769TxcFq"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE\n",
    "opt = tf.optimizers.Adam(learning_rate=0.02, beta_1=0.99, epsilon=1e-1)\n",
    "loops = 100\n",
    "iters_per_loop = 10\n",
    "\n",
    "file_writer = tf.summary.create_file_writer(\n",
    "    \"logs\" + f\"/stw{style_weight}_cow{content_weight}\" + \"tv_weights_my_image\"\n",
    ")\n",
    "file_writer.set_as_default()\n",
    "\n",
    "for loop in range(loops):\n",
    "    tf.summary.image(\"image\", data=image, step=loop * iters_per_loop)\n",
    "    for it in range(iters_per_loop):\n",
    "        # YOUR CODE\n",
    "        loss = train_step(image, opt)\n",
    "        tf.summary.scalar(\"loss\", data=loss, step=loop * iters_per_loop + it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Gghl5218xcFq"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xax2KxiixcFq"
   },
   "source": [
    "29. Submit this notebook not later than December 11th."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zFdfAEywxcFq"
   },
   "source": [
    "30. Apply Neural Style Transfer to content and style images of your choice. Three (not more and not less) self-created images per group need to be submitted and are also due on Decmeber 11th.\n",
    "\n",
    "The submitted images are intended to participate in a *Neural Art Contest* that will take place towards the end of the semester in the form of a public online poll. The guiding theme of the contest is *Nature*. So your content images should feature something from this context. Apart from using content and style images of your choice, there are several things you could try:\n",
    "\n",
    "- Use a larger value of ```max_dim``` to produce higher-resolution images.\n",
    "- Use constant or random initialization for ```image``` instead of ```content_image```.\n",
    "- Use lists ```content_layers``` and ```style_layers``` that are different from the standard setting.\n",
    "- Modify ```content_weight```, ```style_weight``` and ```tv_weight```.\n",
    "- Replace ```tf.optimizers.Adam``` by another algorithm.\n",
    "- Perform more iterations.\n",
    "- Anything else that comes to your mind.\n",
    "\n",
    "Importantly, you need to use your own code to create the images. Moreover, your submission needs to be reproducible, i.e., you are asked to submit all content, style and generated images Python scripts that can be run to reproduce your submitted images.\n",
    "\n",
    "We recommend to use the GPU cluster, especially when you increase the image resolution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Eq5dJvFqxcFr"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)\n",
    "print(len(tf.config.list_physical_devices(\"GPU\")) > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pEQRYnAyxcFr"
   },
   "outputs": [],
   "source": [
    "##New Images\n",
    "content_image = load_img(\"__disha_chauhan__/content/cont_boat.jpg\", 1024 )\n",
    "style_image = load_img(\"__disha_chauhan__/boat.jpg\", 1024 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ff-2uuvFxcFr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
